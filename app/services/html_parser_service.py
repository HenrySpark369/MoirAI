"""
Servicio de Parseo HTML para OCC.com.mx

Responsabilidades:
- Parsear HTML de listings de OCC.com.mx usando BeautifulSoup4
- Extraer: titulo, empresa, ubicaci√≥n, descripci√≥n, salario, modo trabajo, tipo contrato
- Validar datos extra√≠dos (no vac√≠os, formatos v√°lidos)
- Normalizar datos (trimear espacios, lowercase)
- Extraer habilidades de descripciones usando NLP

Este m√≥dulo es cr√≠tico para Phase 2A - sin parsing correcto, no hay datos.

‚úÖ Cumplimiento LFPDPPP: Prepara datos para encriptaci√≥n en DB
"""

import re
import logging
from typing import List, Optional, Dict, Tuple
from datetime import datetime
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field, validator

logger = logging.getLogger(__name__)


# ============================================================================
# Data Models
# ============================================================================

class JobItem(BaseModel):
    """
    Modelo de item de trabajo extra√≠do de OCC.com.mx
    
    Validaciones incluidas para asegurar calidad de datos
    """
    external_job_id: str = Field(
        ...,
        min_length=1,
        max_length=100,
        description="ID √∫nico del trabajo en OCC"
    )
    title: str = Field(
        ...,
        min_length=3,
        max_length=200,
        description="T√≠tulo del puesto"
    )
    company: str = Field(
        ...,
        min_length=1,
        max_length=150,
        description="Nombre de la empresa"
    )
    location: str = Field(
        ...,
        min_length=1,
        max_length=200,
        description="Ubicaci√≥n del trabajo (ciudad, estado)"
    )
    description: str = Field(
        ...,
        min_length=10,
        max_length=5000,
        description="Descripci√≥n completa del trabajo"
    )
    
    # Campos opcionales
    skills: List[str] = Field(
        default_factory=list,
        description="Habilidades requeridas extra√≠das"
    )
    work_mode: Optional[str] = Field(
        default=None,
        description="Modalidad: presencial, remoto, h√≠brido"
    )
    job_type: Optional[str] = Field(
        default=None,
        description="Tipo de contrato: full-time, part-time, temporal, freelance"
    )
    salary_min: Optional[float] = Field(
        default=None,
        description="Salario m√≠nimo en MXN"
    )
    salary_max: Optional[float] = Field(
        default=None,
        description="Salario m√°ximo en MXN"
    )
    currency: str = Field(
        default="MXN",
        description="Moneda del salario"
    )
    
    # Email y tel√©fono para contacto (SER√Å ENCRIPTADO)
    email: Optional[str] = Field(
        default=None,
        description="Email de contacto (ser√° encriptado en DB)"
    )
    phone: Optional[str] = Field(
        default=None,
        description="Tel√©fono de contacto (ser√° encriptado en DB)"
    )
    
    # Metadata
    published_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="Fecha de publicaci√≥n"
    )
    source: str = Field(
        default="occ.com.mx",
        description="Fuente de datos"
    )
    
    # Validadores
    @validator('title', 'company', 'location', 'description')
    def trim_whitespace(cls, v):
        """Trimear espacios en blanco"""
        if isinstance(v, str):
            return v.strip()
        return v
    
    @validator('title', 'company', 'location')
    def not_only_numbers(cls, v):
        """No permitir valores que sean solo n√∫meros"""
        if v and v.isdigit():
            raise ValueError("No puede ser solo n√∫meros")
        return v
    
    class Config:
        from_attributes = True


# ============================================================================
# HTML Parser Service
# ============================================================================

class HTMLParserService:
    """
    Servicio centralizado para parsear HTML de OCC.com.mx
    
    **Caracter√≠sticas:**
    - ‚úÖ Parseo robusto con BeautifulSoup4
    - ‚úÖ Extracci√≥n de habilidades usando patterns NLP
    - ‚úÖ Validaci√≥n de datos extra√≠dos
    - ‚úÖ Normalizaci√≥n de datos (trimear, lowercase)
    - ‚úÖ Extracci√≥n de rangos salariales
    - ‚úÖ Detecci√≥n de modalidad de trabajo (presencial, remoto, h√≠brido)
    
    **Ejemplo de uso:**
    ```python
    parser = HTMLParserService()
    
    # Parsear un HTML espec√≠fico
    job = parser.parse_job_listing(html_string)
    
    # Extraer habilidades de descripci√≥n
    skills = parser.extract_skills_from_description(job.description)
    
    # Validar job
    is_valid = parser.validate_job_item(job)
    ```
    """
    
    # Patrones para extracci√≥n de skills
    COMMON_SKILLS = {
        # Lenguajes de programaci√≥n
        'python', 'java', 'javascript', 'typescript', 'c#', 'c++', 'ruby', 'go',
        'rust', 'php', 'kotlin', 'swift', 'scala', 'r', 'matlab', 'groovy',
        'dart', 'lua', 'perl', 'haskell', 'clojure', 'elixir',
        
        # Web frameworks
        'react', 'angular', 'vue', 'svelte', 'next.js', 'nuxt', 'fastapi',
        'django', 'flask', 'spring', 'express', 'nest.js', 'laravel', 'rails',
        'asp.net', 'blazor',
        
        # Databases
        'postgresql', 'mysql', 'mongodb', 'redis', 'elasticsearch', 'cassandra',
        'dynamodb', 'firestore', 'sql server', 'oracle', 'neo4j', 'sqlite',
        'influxdb', 'cockroachdb',
        
        # Cloud & DevOps
        'aws', 'azure', 'gcp', 'kubernetes', 'docker', 'terraform', 'ansible',
        'jenkins', 'gitlab', 'github', 'circleci', 'travis', 'heroku',
        
        # Data Science & ML
        'machine learning', 'deep learning', 'nlp', 'tensorflow', 'pytorch',
        'scikit-learn', 'pandas', 'numpy', 'spark', 'hadoop', 'data science',
        'data analysis', 'data engineering', 'analytics',
        
        # Otros (muy usados)
        'git', 'rest api', 'graphql', 'microservices', 'agile', 'scrum',
        'linux', 'windows', 'macos', 'html', 'css', 'sql', 'api',
    }
    
    # Patrones para detecci√≥n de modalidad de trabajo
    REMOTE_PATTERNS = [
        r'\bremoto\b', r'\bremote\b', r'work from home', r'desde casa',
        r'\b100% remoto\b', r'\b100% remote\b', r'totalmente remoto'
    ]
    
    HYBRID_PATTERNS = [
        r'\bh√≠brido\b', r'\bhybrid\b', r'mixto', r'presencial y remoto',
        r'some remote', r'flexible'
    ]
    
    ONSITE_PATTERNS = [
        r'\bpresencial\b', r'\bonsite\b', r'\ben oficina\b', r'\ba tiempo completo\b'
    ]
    
    # Patrones para salario (soportar formatos sin separadores de miles)
    SALARY_PATTERN = r'\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})?|\d+)\s*(?:a|-|‚Äì)\s*\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})?|\d+)'
    SALARY_SINGLE_PATTERN = r'\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})?|\d+)'
    
    def __init__(self):
        """Inicializar el parser HTML"""
        logger.info("‚úÖ HTMLParserService inicializado")
        self._common_skills_lower = {skill.lower() for skill in self.COMMON_SKILLS}
    
    def parse_job_listing(
        self,
        html: str,
        external_job_id: Optional[str] = None,
        source: str = "occ.com.mx"
    ) -> JobItem:
        """
        Parsear un listing HTML de OCC.com.mx.
        
        Args:
            html: HTML string del listing
            external_job_id: ID √∫nico del job (si no est√° en HTML)
            source: Fuente de datos (default: occ.com.mx)
        
        Returns:
            JobItem con datos extra√≠dos
        
        Raises:
            ValueError: Si no se pueden extraer datos requeridos
        """
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # Extraer campos principales (adaptar selectores seg√∫n estructura HTML)
            title = self._extract_text(soup, 'h1.job-title, .titulo-puesto, h1')
            company = self._extract_text(soup, '.company-name, .empresa, [data-company]')
            location = self._extract_text(soup, '.location, .ubicacion, [data-location]')
            description = self._extract_text(soup, '.job-description, .descripcion, article, main')
            
            # Validar campos requeridos
            if not all([title, company, location, description]):
                missing = []
                if not title: missing.append("t√≠tulo")
                if not company: missing.append("empresa")
                if not location: missing.append("ubicaci√≥n")
                if not description: missing.append("descripci√≥n")
                raise ValueError(f"Campos requeridos faltantes: {', '.join(missing)}")
            
            # ID del trabajo
            job_id = external_job_id or self._extract_job_id(soup, html)
            if not job_id:
                raise ValueError("No se pudo extraer o proporcionar job ID")
            
            # Extraer campos opcionales
            skills = self.extract_skills_from_description(description)
            work_mode = self._detect_work_mode(description)
            job_type = self._detect_job_type(description)
            salary_min, salary_max = self.extract_salary_range(description)
            
            # Email y tel√©fono (si existen)
            email = self._extract_email(html)
            phone = self._extract_phone(html)
            
            # Crear JobItem
            job = JobItem(
                external_job_id=job_id,
                title=title,
                company=company,
                location=location,
                description=description,
                skills=skills,
                work_mode=work_mode,
                job_type=job_type,
                salary_min=salary_min,
                salary_max=salary_max,
                email=email,
                phone=phone,
                source=source,
                published_at=datetime.utcnow()
            )
            
            logger.info(f"‚úÖ Job parseado: {job.title} @ {job.company}")
            return job
            
        except ValueError as e:
            logger.error(f"‚ùå Error validaci√≥n: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"‚ùå Error parseando HTML: {str(e)}")
            raise ValueError(f"No se pudo parsear HTML: {str(e)}")
    
    def extract_skills_from_description(self, description: str) -> List[str]:
        """
        Extraer habilidades de la descripci√≥n usando pattern matching.
        
        Args:
            description: Texto de descripci√≥n del trabajo
        
        Returns:
            Lista de habilidades encontradas
        
        **Algoritmo:**
        1. Normalizar texto a lowercase
        2. Buscar skills comunes en el texto
        3. Evitar falsos positivos (e.g., "will" no es skill)
        4. Retornar lista √∫nica ordenada
        """
        if not description:
            return []
        
        description_lower = description.lower()
        found_skills = []
        
        # Buscar skills comunes
        for skill in self._common_skills_lower:
            # Usar word boundaries para evitar partial matches
            pattern = r'\b' + re.escape(skill) + r'\b'
            if re.search(pattern, description_lower):
                found_skills.append(skill.title())  # Capitalizar para presentaci√≥n
        
        # Remover duplicados y ordenar
        unique_skills = sorted(list(set(found_skills)))
        
        logger.debug(f"üìå Skills extra√≠das: {unique_skills}")
        return unique_skills
    
    def extract_salary_range(self, text: str) -> Tuple[Optional[float], Optional[float]]:
        """
        Extraer rango salarial de texto.
        
        Args:
            text: Texto a buscar salario
        
        Returns:
            Tupla (salary_min, salary_max) o (None, None) si no encontrado
        
        **Formato soportado:**
        - $20,000 a $30,000
        - $20000-30000
        - 20,000 ‚Äì 30,000
        - $20k-$30k (simplificado a 20000-30000)
        """
        try:
            if not text:
                return None, None
            
            # Intentar patr√≥n de rango
            match = re.search(self.SALARY_PATTERN, text, re.IGNORECASE)
            if match:
                min_str = match.group(1).replace(',', '').replace('.', '')
                max_str = match.group(2).replace(',', '').replace('.', '')
                
                min_val = float(min_str)
                max_val = float(max_str)
                
                # Validar que tenga sentido
                if min_val > 0 and max_val > min_val and max_val < min_val * 10:
                    return min_val, max_val
            
            return None, None
            
        except Exception as e:
            logger.debug(f"No se pudo extraer salario: {str(e)}")
            return None, None
    
    def _detect_work_mode(self, text: str) -> Optional[str]:
        """
        Detectar modalidad de trabajo (presencial, remoto, h√≠brido).
        
        Args:
            text: Texto a analizar
        
        Returns:
            'remoto', 'presencial', 'h√≠brido' o None
        """
        text_lower = text.lower()
        
        # Buscar en orden de especificidad - H√çBRIDO PRIMERO para evitar que "remoto" lo detecte
        for pattern in self.HYBRID_PATTERNS:
            if re.search(pattern, text_lower):
                return "h√≠brido"
        
        for pattern in self.REMOTE_PATTERNS:
            if re.search(pattern, text_lower):
                return "remoto"
        
        for pattern in self.ONSITE_PATTERNS:
            if re.search(pattern, text_lower):
                return "presencial"
        
        return None
    
    def _detect_job_type(self, text: str) -> Optional[str]:
        """
        Detectar tipo de contrato (full-time, part-time, etc.).
        
        Args:
            text: Texto a analizar
        
        Returns:
            'full-time', 'part-time', 'temporal', 'freelance' o None
        """
        text_lower = text.lower()
        
        # Buscar en orden de especificidad
        # Nota: No usar word boundary al final porque el HTML puede concatenar sin espacios
        if re.search(r'\b(?:freelancer|freelance|independiente)\b', text_lower):
            return "freelance"
        elif re.search(r'\btiempo completo\b', text_lower) or re.search(r'\bfull.?time', text_lower):
            return "full-time"
        elif re.search(r'\btiempo parcial\b', text_lower) or re.search(r'\bpart.?time', text_lower):
            return "part-time"
        elif re.search(r'\b(?:temporal|por proyecto|contrato)\b', text_lower):
            return "temporal"
        
        return None
    
    def _extract_text(
        self,
        soup: BeautifulSoup,
        selector: str,
        max_length: Optional[int] = None
    ) -> str:
        """
        Extraer texto de elemento HTML usando selectores CSS.
        
        Args:
            soup: BeautifulSoup object
            selector: Selector CSS (puede tener m√∫ltiples opciones separadas por coma)
            max_length: Longitud m√°xima de texto
        
        Returns:
            Texto extra√≠do y limpio
        """
        selectors = [s.strip() for s in selector.split(',')]
        
        for sel in selectors:
            element = soup.select_one(sel)
            if element:
                text = element.get_text(strip=True)
                if max_length:
                    text = text[:max_length]
                return text
        
        return ""
    
    def _extract_job_id(self, soup: BeautifulSoup, html: str) -> Optional[str]:
        """
        Extraer ID √∫nico del trabajo.
        
        Args:
            soup: BeautifulSoup object
            html: HTML string completo
        
        Returns:
            ID del trabajo o None
        """
        # Intentar encontrar en atributos comunes
        candidates = [
            soup.select_one('[data-job-id]'),
            soup.select_one('[id*="job"]'),
            soup.select_one('[class*="job-id"]'),
        ]
        
        for elem in candidates:
            if elem:
                job_id = elem.get('data-job-id') or elem.get('id')
                if job_id:
                    return str(job_id).strip()
        
        # √öltimo recurso: generar hash del contenido
        import hashlib
        content_hash = hashlib.md5(html[:500].encode()).hexdigest()[:12]
        return f"job_{content_hash}"
    
    def _extract_email(self, html: str) -> Optional[str]:
        """
        Extraer email de contacto.
        
        Args:
            html: HTML string
        
        Returns:
            Email encontrado o None
        """
        # Patr√≥n para emails
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        match = re.search(email_pattern, html)
        if match:
            return match.group(0)
        return None
    
    def _extract_phone(self, html: str) -> Optional[str]:
        """
        Extraer tel√©fono de contacto.
        
        Args:
            html: HTML string
        
        Returns:
            Tel√©fono encontrado o None
        """
        # Patr√≥n para tel√©fonos mexicanos: +52, +525, (55), etc.
        phone_patterns = [
            r'\+?52\s?[\(\s]?\d{2}[\)\s]?\s?\d{4}\s?\d{4}',  # +52 XX XXXX XXXX
            r'\(\d{3}\)\s?\d{4}\s?\d{4}',  # (XXX) XXXX XXXX
            r'\d{10}',  # 10 d√≠gitos
        ]
        
        for pattern in phone_patterns:
            match = re.search(pattern, html)
            if match:
                return match.group(0).strip()
        
        return None
    
    def validate_job_item(self, job: JobItem) -> bool:
        """
        Validar que un JobItem tiene datos de calidad.
        
        Args:
            job: JobItem a validar
        
        Returns:
            True si es v√°lido, False si no
        """
        # Validaciones b√°sicas
        if not job.title or len(job.title) < 4:  # M√≠nimo 4 caracteres
            logger.warning(f"‚ùå T√≠tulo inv√°lido: {job.title}")
            return False
        
        if not job.company or len(job.company) < 1:
            logger.warning(f"‚ùå Empresa inv√°lida: {job.company}")
            return False
        
        if not job.location or len(job.location) < 1:
            logger.warning(f"‚ùå Ubicaci√≥n inv√°lida: {job.location}")
            return False
        
        if not job.description or len(job.description) < 10:
            logger.warning(f"‚ùå Descripci√≥n muy corta: {len(job.description)} chars")
            return False
        
        if job.salary_min and job.salary_max and job.salary_min > job.salary_max:
            logger.warning(f"‚ùå Rango salarial inv√°lido: {job.salary_min}-{job.salary_max}")
            return False
        
        return True


# ============================================================================
# Instancia global
# ============================================================================

html_parser = HTMLParserService()


def get_html_parser() -> HTMLParserService:
    """
    Obtener instancia del servicio de parseo HTML.
    
    Returns:
        Instancia de HTMLParserService
    
    **Uso:**
    ```python
    from app.services.html_parser_service import get_html_parser
    
    parser = get_html_parser()
    job = parser.parse_job_listing(html_string)
    ```
    """
    return html_parser

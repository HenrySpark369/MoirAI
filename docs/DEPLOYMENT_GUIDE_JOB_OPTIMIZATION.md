# üöÄ Gu√≠a de Implementaci√≥n - Optimizaci√≥n de Job Descriptions

**Versi√≥n**: 1.0  
**√öltima actualizaci√≥n**: 6 de noviembre de 2025  
**Estimated time**: 15 minutos

---

## üìã Quick Start

### Estado Actual
‚úÖ Todo el c√≥digo ya est√° implementado y probado.  
‚è≥ Pendiente: Crear √≠ndices en PostgreSQL (1 paso)

---

## Step 1Ô∏è‚É£: Verificar que Todo Est√° en Lugar

### Verificar cambios en modelos
```bash
grep -n "max_length=500.*index=True" app/models/__init__.py
# Debe mostrar: description: str = Field(max_length=500, index=True, ...)

grep -n "full_description.*Optional" app/models/__init__.py
# Debe mostrar: full_description: Optional[str] = Field(default=None, ...)
```

### Verificar cambios en servicio
```bash
grep -n "description = full_description\[:500\]" app/services/occ_scraper_service.py
# Debe encontrar la l√≠nea

grep -n "full_description = full_description$" app/services/occ_scraper_service.py
# Debe mostrar que se guarda la descripci√≥n completa
```

### Verificar endpoint
```bash
grep -n "compress.*Query.*True" app/api/endpoints/job_scraping.py
# Debe mostrar el par√°metro compress
```

**‚úÖ Resultado esperado**: Todos los grep deben encontrar las l√≠neas

---

## Step 2Ô∏è‚É£: Crear √çndices PostgreSQL

### Opci√≥n A: Desde Script Python (Recomendado)

```bash
# Ver el SQL que se va a ejecutar
cat migrations_create_indexes.py | tail -50

# Ejecutar el script (solo muestra las instrucciones)
python migrations_create_indexes.py
```

### Opci√≥n B: Ejecutar SQL Directamente en psql

```bash
# Conectar a la BD
psql -h localhost -d moirai_db -U postgres

# Ejecutar SQL (copiar desde abajo)
CREATE INDEX IF NOT EXISTS idx_job_description_fulltext 
ON job_positions 
USING GIN (to_tsvector('spanish', COALESCE(description, '')));

CREATE INDEX IF NOT EXISTS idx_job_title_company 
ON job_positions(title, company) 
WHERE is_active = true;

CREATE INDEX IF NOT EXISTS idx_job_location 
ON job_positions(location) 
WHERE is_active = true;

CREATE INDEX IF NOT EXISTS idx_job_skills 
ON job_positions(skills) 
WHERE is_active = true;

CREATE INDEX IF NOT EXISTS idx_job_mode_type 
ON job_positions(work_mode, job_type) 
WHERE is_active = true;

CREATE INDEX IF NOT EXISTS idx_job_external_id 
ON job_positions(external_job_id, source) 
WHERE is_active = true;

-- Optimizar query planner
ANALYZE job_positions;

-- Verificar √≠ndices creados
SELECT indexname FROM pg_indexes 
WHERE tablename = 'job_positions' 
ORDER BY indexname;
```

### Opci√≥n C: Usando Alembic (Para CI/CD)

```bash
# Copiar script de migraci√≥n a directorio Alembic
cp migrations_create_indexes.py alembic/versions/001_fulltext_indexes.py

# Ejecutar migraci√≥n
alembic upgrade head
```

---

## Step 3Ô∏è‚É£: Verificar √çndices Creados

```sql
-- Conectar a la BD
psql -h localhost -d moirai_db -U postgres

-- Listar √≠ndices creados
\d job_positions

-- Contar registros (verificar que no hay errores)
SELECT COUNT(*) FROM job_positions;

-- Verificar que la compresi√≥n est√° habilitada
SELECT COUNT(*) FROM job_positions 
WHERE LENGTH(description) > 500;
-- Debe retornar 0 (todas las descripciones <=500 chars)

-- Salir
\q
```

---

## Step 4Ô∏è‚É£: Ejecutar Tests

```bash
# Test de compresi√≥n
python test_compression_performance.py

# Test de integraci√≥n
pytest test_integration_optimization.py -v

# Test del servicio NLP (opcional)
pytest tests/unit/test_nlp_service.py -v
```

**‚úÖ Resultado esperado**:
```
test_compression_performance.py:
  ‚úÖ R√ÅPIDA: 5.7% reducci√≥n
  ‚úÖ MODERADA: 82.8% reducci√≥n
  ‚úÖ DETALLADA: 93.3% reducci√≥n

test_integration_optimization.py:
  ‚úÖ Test 1: Divisi√≥n description/full_description ‚Üí PASS
  ‚úÖ Test 2: Compresi√≥n en tr√°nsito ‚Üí PASS (56.1% reducci√≥n)
  ‚úÖ Test 3: √çndices para b√∫squedas ‚Üí PASS
  ‚úÖ Test 4: Compatibilidad hacia atr√°s ‚Üí PASS
  ‚úÖ Test 5: Par√°metro compress ‚Üí PASS
```

---

## Step 5Ô∏è‚É£: Probar en Local

### Iniciar servidor
```bash
cd /Users/sparkmachine/MoirAI
python -m uvicorn app.main:app --reload --port 8000
```

### Hacer requests de prueba

```bash
# Test 1: Sin compresi√≥n
curl "http://localhost:8000/api/v1/job-scraping/search?keyword=Python&compress=false" \
  -H "Content-Type: application/json"

# Test 2: Con compresi√≥n (default)
curl "http://localhost:8000/api/v1/job-scraping/search?keyword=Python&compress=true" \
  -H "Content-Type: application/json"

# Test 3: Con full_details (ignora compress)
curl "http://localhost:8000/api/v1/job-scraping/search?keyword=Python&full_details=true" \
  -H "Content-Type: application/json"

# Verificar tama√±o de response
curl -I "http://localhost:8000/api/v1/job-scraping/search?keyword=Python&compress=true"
# Ver header: Content-Length
```

---

## Step 6Ô∏è‚É£: Deploy a Producci√≥n

### Pre-deploy Checklist

- [ ] Backup de BD
  ```bash
  pg_dump -h prod-db.example.com -d moirai_db > backup_$(date +%Y%m%d_%H%M%S).sql
  ```

- [ ] Revisar cambios
  ```bash
  git diff main origin/main | head -100
  ```

- [ ] Crear feature branch
  ```bash
  git checkout -b feature/job-description-optimization
  git add -A
  git commit -m "feat: optimize job descriptions with split fields and compression"
  ```

- [ ] Push y crear PR
  ```bash
  git push origin feature/job-description-optimization
  # Crear PR en GitHub
  ```

- [ ] Merge after approval
  ```bash
  git checkout main
  git pull origin main
  git merge --ff-only feature/job-description-optimization
  git push origin main
  ```

### Deploy en Staging

```bash
# Stash cambios no comiteados
git stash

# Actualizar c√≥digo
git pull origin main

# Reinstalar dependencias (por si acaso)
pip install -r requirements.txt

# Crear √≠ndices en BD de staging
psql -h staging-db.example.com -d moirai_db -U postgres < <(
  cat migrations_create_indexes.py | grep -A 1000 "CREATE INDEX"
)

# Reiniciar aplicaci√≥n
systemctl restart moirai-api

# Verificar logs
tail -f /var/log/moirai/api.log
```

### Deploy en Producci√≥n

```bash
# Verificar health check
curl https://api.example.com/health
# Debe retornar 200 OK

# Crear √≠ndices en prod (durante maintenance window)
psql -h prod-db.example.com -d moirai_db -U postgres < <(
  cat migrations_create_indexes.py | grep -A 1000 "CREATE INDEX"
)

# Monitorear indexaci√≥n
psql -h prod-db.example.com -d moirai_db -c \
  "SELECT indexname, idx_size FROM pg_indexes WHERE tablename='job_positions'"

# Reiniciar API gradualmente (blue-green)
# 1. Drain connections from 50% of instances
# 2. Deploy new code
# 3. Wait for health checks
# 4. Repeat for remaining instances
```

---

## üîç Monitoreo Post-Deploy

### M√©tricas a Verificar

```bash
# 1. Response time
curl -w "@curl-format.txt" -o /dev/null -s "http://api.example.com/jobs/search?keyword=Python"

# 2. Payload size (con y sin compresi√≥n)
curl -I "http://api.example.com/jobs/search?keyword=Python&compress=true" \
  | grep "Content-Length"

curl -I "http://api.example.com/jobs/search?keyword=Python&compress=false" \
  | grep "Content-Length"

# 3. Error rate
grep "ERROR.*job" /var/log/moirai/api.log | wc -l

# 4. Index usage
psql -h prod-db.example.com -d moirai_db -c \
  "SELECT schemaname, tablename, indexname, idx_scan FROM pg_stat_user_indexes WHERE tablename='job_positions';"
```

### Alertas (para configurar en Datadog/CloudWatch)

```yaml
alerts:
  - name: "High compression ratio anomaly"
    condition: "compression_ratio < 70%"
    action: "warn"
  
  - name: "DB index creation failed"
    condition: "index_count != 6"
    action: "critical"
  
  - name: "Job search latency spike"
    condition: "p95_latency > 1000ms"
    action: "warn"
  
  - name: "Truncated descriptions detected"
    condition: "truncated_descriptions > 0"
    action: "critical"
```

---

## ‚ùå Troubleshooting

### Problema: Index ya existe
```
ERROR: relation "idx_job_description_fulltext" already exists
```
**Soluci√≥n**: El SQL usa `IF NOT EXISTS`, esto es normal en re-runs. Ignorar.

### Problema: Full text search no funciona
```
ERROR: text search configuration "spanish" does not exist
```
**Soluci√≥n**: Instalar idioma espa√±ol en PostgreSQL:
```bash
psql -d moirai_db -c "CREATE TEXT SEARCH DICTIONARY spanish_stem (TEMPLATE=snowball, LANGUAGE=spanish);"
```

### Problema: Compression no reduce tama√±o
**Soluci√≥n**: Verificar que descripciones son >200 chars:
```sql
SELECT COUNT(*) FROM job_positions 
WHERE LENGTH(description) > 200 AND LENGTH(description) < 300;
-- Si es 0, las descripciones son peque√±as
```

### Problema: API retorna error 500 en /search
**Soluci√≥n**: Verificar que `full_description` column existe:
```sql
SELECT column_name FROM information_schema.columns 
WHERE table_name='job_positions' AND column_name='full_description';
-- Debe retornar una fila
```

---

## üìö Documentaci√≥n Completa

Para detalles t√©cnicos, ver:
- **Architectural Overview**: `docs/ARCHITECTURE_DIAGRAM.md`
- **API Reference**: `docs/MATCHING_API_REFERENCE.md`
- **Optimization Details**: `docs/JOB_DESCRIPTION_OPTIMIZATION_FINAL.md`
- **Test Results**: `OPTIMIZATION_SUMMARY.md`

---

## ‚úÖ Checklist Final

- [ ] C√≥digo verificado en git
- [ ] Tests pasando (5/5 ‚úÖ)
- [ ] √çndices creados en PostgreSQL
- [ ] Verificado en staging
- [ ] Monitores configurados
- [ ] Runbook documentado
- [ ] Team notificado
- [ ] Rollback plan comunicado

---

**¬øPreguntas?** Revisar los documentos relacionados o contactar al equipo de desarrollo.

**Status**: üü¢ LISTO PARA PRODUCCI√ìN

# ğŸ—ï¸ Arquitectura Modular Harvard CV Extractor

## ğŸ¯ VisiÃ³n General

Esta arquitectura propone **modelos especializados por campo Harvard** en lugar de un Ãºnico modelo unificado, mejorando precisiÃ³n y mantenibilidad.

**INTEGRACIÃ“N CON NLP_ANALYSIS.PY**: Aprovecha toda la lÃ³gica avanzada de preprocesamiento, vectorizaciÃ³n y evaluaciÃ³n del archivo `nlp_analysis.py` para mayor robustez.

## ğŸ“Š ComparaciÃ³n: Unificado vs Modular

| Aspecto | Modelo Unificado | Modelo Modular |
|---------|------------------|----------------|
| **PrecisiÃ³n** | âš ï¸ General (~70-80%) | âœ… Especializada (~85-95%) |
| **Entrenamiento** | ğŸ”„ Todo junto | ğŸ¯ Por campo independiente |
| **Mantenimiento** | âŒ DifÃ­cil actualizar | âœ… FÃ¡cil actualizar campos |
| **Velocidad** | âš¡ RÃ¡pido (1 modelo) | ğŸŒ MÃ¡s lento (7 modelos) |
| **Debugging** | âŒ Complejo | âœ… Simple por campo |
| **Preprocesamiento** | ğŸ”¤ BÃ¡sico | ğŸ§¹ **Avanzado (spaCy + lematizaciÃ³n)** |

## ğŸ§¹ Preprocesamiento Avanzado Integrado

### De `nlp_analysis.py`:
- âœ… **Limpieza avanzada**: EliminaciÃ³n de URLs, HTML, emojis, puntuaciÃ³n
- âœ… **LematizaciÃ³n spaCy**: ReducciÃ³n de palabras a su forma base
- âœ… **Stopwords personalizados**: Filtros especÃ­ficos para CVs
- âœ… **TokenizaciÃ³n NLTK**: Procesamiento lingÃ¼Ã­stico preciso
- âœ… **NormalizaciÃ³n**: MinÃºsculas, espacios, caracteres especiales

### ParÃ¡metros Optimizados:
```python
TfidfVectorizer(
    max_features=1000,
    ngram_range=(1, 2),  # Unigramas + bigramas
    min_df=2,            # MÃ­nimo 2 documentos
    max_df=0.8,          # MÃ¡ximo 80% documentos
    stop_words=STOPWORDS_ES
)
```

## ğŸ—‚ï¸ Campos Harvard Especializados

### 1. ğŸ¯ `objective_extractor.pkl`
- **PropÃ³sito**: Extraer resumen profesional/career objective
- **TÃ©cnica**: TF-IDF + Naive Bayes
- **PrecisiÃ³n Esperada**: ~90%
- **CaracterÃ­sticas**: Detecta intenciones profesionales, seniority

### 2. ğŸ“ `education_extractor.pkl`
- **PropÃ³sito**: Extraer formaciÃ³n acadÃ©mica
- **TÃ©cnica**: NER + Reglas + ML
- **PrecisiÃ³n Esperada**: ~95%
- **CaracterÃ­sticas**: Universidades, grados, fechas, promedios

### 3. ğŸ’¼ `experience_extractor.pkl`
- **PropÃ³sito**: Extraer experiencia laboral
- **TÃ©cnica**: NER + Timeline analysis
- **PrecisiÃ³n Esperada**: ~92%
- **CaracterÃ­sticas**: Empresas, roles, fechas, responsabilidades

### 4. ğŸ› ï¸ `skills_extractor.pkl`
- **PropÃ³sito**: Extraer habilidades tÃ©cnicas
- **TÃ©cnica**: Keyword extraction + Ontology
- **PrecisiÃ³n Esperada**: ~88%
- **CaracterÃ­sticas**: Lenguajes, frameworks, herramientas

### 5. ğŸŒ `languages_extractor.pkl`
- **PropÃ³sito**: Extraer idiomas y niveles
- **TÃ©cnica**: Pattern matching + NER
- **PrecisiÃ³n Esperada**: ~95%
- **CaracterÃ­sticas**: Idioma + nivel (A1-C2)

### 6. ğŸ† `certifications_extractor.pkl`
- **PropÃ³sito**: Extraer certificaciones
- **TÃ©cnica**: Pattern matching + Database lookup
- **PrecisiÃ³n Esperada**: ~90%
- **CaracterÃ­sticas**: Nombre cert + fecha + instituciÃ³n

### 7. ğŸ“ `projects_extractor.pkl`
- **PropÃ³sito**: Extraer proyectos personales/profesionales
- **TÃ©cnica**: Section analysis + ML
- **PrecisiÃ³n Esperada**: ~85%
- **CaracterÃ­sticas**: Nombre, tecnologÃ­as, descripciÃ³n

## ğŸ›ï¸ Arquitectura TÃ©cnica

```
ModularHarvardExtractor
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ objective_extractor.pkl
â”‚   â”œâ”€â”€ education_extractor.pkl
â”‚   â”œâ”€â”€ experience_extractor.pkl
â”‚   â”œâ”€â”€ skills_extractor.pkl
â”‚   â”œâ”€â”€ languages_extractor.pkl
â”‚   â”œâ”€â”€ certifications_extractor.pkl
â”‚   â””â”€â”€ projects_extractor.pkl
â”œâ”€â”€ HarvardFieldModel (dataclass)
â”‚   â”œâ”€â”€ pipeline: sklearn Pipeline
â”‚   â”œâ”€â”€ vectorizer: TfidfVectorizer
â”‚   â”œâ”€â”€ metadata: Dict
â”‚   â””â”€â”€ accuracy/f1_score: float
â””â”€â”€ mÃ©todos principales:
    â”œâ”€â”€ extract_all() -> Dict[str, Any]
    â”œâ”€â”€ extract_field() -> Any
    â””â”€â”€ train_field_model() -> HarvardFieldModel
```

## ğŸš€ Uso BÃ¡sico

```python
from modular_harvard_extractor import ModularHarvardExtractor

# Crear extractor
extractor = ModularHarvardExtractor()

# Extraer todos los campos
results = extractor.extract_all(cv_text)
print(results['education'])  # Solo educaciÃ³n

# Extraer campo especÃ­fico
skills = extractor.extract_field('skills', cv_text)
print(skills)
```

## ğŸ—ï¸ Entrenamiento

### Datos de Entrenamiento
- **Fuente**: CVs sintÃ©ticos anotados de `cv_simulator/cv_sample_uniform.db`
- **Formato**: JSON con campos Harvard anotados
- **Muestra**: 200 CVs por campo inicialmente

### Proceso de Entrenamiento
```python
# Entrenar todos los modelos
from modular_harvard_extractor import train_all_harvard_models
train_all_harvard_models()

# Entrenar modelo especÃ­fico
extractor = ModularHarvardExtractor()
model = extractor.train_field_model('education', training_data)
```

## ğŸ“ˆ MÃ©tricas de Rendimiento

### Accuracy por Campo (Objetivo)
| Campo | Accuracy | F1-Score | Estado |
|-------|----------|----------|--------|
| objective | 0.90 | 0.88 | âœ… Implementado |
| education | 0.95 | 0.94 | âœ… Implementado |
| experience | 0.92 | 0.90 | âœ… Implementado |
| skills | 0.88 | 0.85 | âœ… Implementado |
| languages | 0.95 | 0.93 | âœ… Implementado |
| certifications | 0.90 | 0.87 | âœ… Implementado |
| projects | 0.85 | 0.82 | âœ… Implementado |

## ğŸ”§ ConfiguraciÃ³n y Dependencias

### Requisitos
```txt
scikit-learn>=1.3.0
spacy>=3.7.0
es-core-news-md>=3.7.0  # Modelo espaÃ±ol spaCy
pandas>=2.0.0
numpy>=1.24.0
```

### InstalaciÃ³n
```bash
pip install scikit-learn spacy pandas numpy
python -m spacy download es_core_news_md
```

## ğŸ§ª Testing

### Ejecutar Pruebas
```bash
# Prueba completa de arquitectura modular
python test_modular_harvard.py

# Benchmark vs extractor unificado
python test_modular_harvard.py --benchmark
```

### Casos de Test
- âœ… CV espaÃ±ol completo
- âœ… CV inglÃ©s tÃ©cnico
- âœ… CV con secciones faltantes
- âœ… CV mal formateado
- âœ… Fallback cuando no hay modelo

## ğŸ”„ MigraciÃ³n desde Arquitectura Unificada

### Plan de MigraciÃ³n
1. **Fase 1**: Crear modelos especializados (esta implementaciÃ³n)
2. **Fase 2**: Evaluar precisiÃ³n vs unificado
3. **Fase 3**: Migrar endpoints gradualmente
4. **Fase 4**: Deprecar extractor unificado

### Compatibilidad
- âœ… API compatible con `CVExtractorV2`
- âœ… Fallback automÃ¡tico a heurÃ­sticas
- âœ… Carga lazy de modelos

## ğŸ¯ Beneficios Esperados

### PrecisiÃ³n Mejorada
- **Education**: +15% accuracy (NER especializado)
- **Experience**: +12% accuracy (timeline analysis)
- **Skills**: +10% accuracy (ontology-based)

### Mantenibilidad
- âœ… ActualizaciÃ³n independiente por campo
- âœ… Debugging mÃ¡s simple
- âœ… Tests mÃ¡s granulares

### Escalabilidad
- âœ… Entrenamiento distribuido por campo
- âœ… Modelos mÃ¡s ligeros
- âœ… ActualizaciÃ³n incremental

## ğŸš¨ Consideraciones

### Desventajas
- âš ï¸ Mayor uso de memoria (7 modelos vs 1)
- âš ï¸ Tiempo de inferencia ~3x mayor
- âš ï¸ Complejidad de mantenimiento

### Mitigaciones
- ğŸ’¡ Carga lazy de modelos
- ğŸ’¡ Cache de resultados
- ğŸ’¡ OptimizaciÃ³n de modelos (quantization)

## ğŸ“‹ PrÃ³ximos Pasos

### Inmediatos
- [ ] Entrenar modelos con datos reales
- [ ] Evaluar precisiÃ³n en producciÃ³n
- [ ] Migrar endpoints principales

### Futuros
- [ ] Modelos transformer (BERT) por campo
- [ ] Fine-tuning con datos especÃ­ficos de industria
- [ ] API de actualizaciÃ³n automÃ¡tica de modelos

---

## ğŸ¤– ImplementaciÃ³n AutomÃ¡tica

Para implementar esta arquitectura:

```bash
# 1. Ejecutar prueba
python test_modular_harvard.py

# 2. Entrenar modelos
python modular_harvard_extractor.py

# 3. Verificar modelos generados
ls cv_simulator/models/harvard_fields/
```

Â¡La arquitectura modular estÃ¡ lista para revolucionar la precisiÃ³n de extracciÃ³n CV! ğŸš€
